{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "HW4.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0KKC3O3QiIi4"
      },
      "source": [
        "#COMPSCI 546: Applied Information Retrieval \n",
        "##Assignment 4: Relevance Models (Total : 100 points)\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JuVqvXU6ijXi"
      },
      "source": [
        "# Download input files and code"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "SMU5d1a-jCG-"
      },
      "source": [
        "Please execute the cell below to download the input files. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YM1igiBMcIB8"
      },
      "source": [
        "\n",
        "import os\n",
        "from pydrive.auth import GoogleAuth\n",
        "from pydrive.drive import GoogleDrive\n",
        "from google.colab import auth\n",
        "from oauth2client.client import GoogleCredentials\n",
        "\n",
        "auth.authenticate_user()\n",
        "gauth = GoogleAuth()\n",
        "gauth.credentials = GoogleCredentials.get_application_default()\n",
        "drive = GoogleDrive(gauth)\n",
        "\n",
        "\n",
        "import os\n",
        "import zipfile\n",
        "\n",
        "download = drive.CreateFile({'id': '1CLVPQ0HADjmE0cPthdZ628aIYc8yvMdq'})\n",
        "download.GetContentFile('HW04.zip')\n",
        "\n",
        "with zipfile.ZipFile('HW04.zip', 'r') as zip_file:\n",
        "    zip_file.extractall('./')\n",
        "os.remove('HW04.zip')\n",
        "# We will use hw1 as our working directory\n",
        "os.chdir('HW04')\n",
        "\n",
        "#Setting the input files \n",
        "queries_file = \"queries_tok_clean_kstem\"\n",
        "col = \"antique-collection.tok.clean_kstem\"\n",
        "query_pass = \"query_pass\"    "
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "T9GqDu_ilscP"
      },
      "source": [
        "# 1 : Initial Data Setup (20 points)\n",
        "\n",
        "We use files from the ANTIQUE  [https://arxiv.org/pdf/1905.08957.pdf] dataset for this assignment. As described in the previous assignments, this is a passage retrieval dataset. \n",
        "\n",
        "The description of the input files provided for this assignment is given below.\n",
        "\n",
        "**Query File**\n",
        "\n",
        "We randomly sampled a set of 5 queries from the test set of the ANTIQUE dataset. Each row of the input file contains the following information:\n",
        "\n",
        "*query_id query_text*\n",
        "\n",
        "The id and text information is tab separated. query_id is a unique identifier for a query and query text has been pre-processed to remove punctutation, tokenised and stemmed using the Krovetz stemmer.  \n",
        "\n",
        "**Collection file**\n",
        "\n",
        "Each row of the file consists of the following information:\n",
        "\n",
        "*passage_id  passage_text*\n",
        "\n",
        "The id and text information is tab separated. The passage text has been pre-processed to remove punctutation, tokenised and stemmed using the Krovetz stemmer (same as queries). The terms in the passage text can be accessed by splitting the text based on space.\n",
        "\n",
        "**Query Feedback Passages**\n",
        "\n",
        "This file consists of queries and 10 feedback passages corresponding to each query.  Each row of the file consists of the following information:\n",
        "\n",
        "*query_id  passage_id1 passage_id2 ......passage_id10*\n",
        "\n",
        "The entries are space separated. The first column is the query_id followed by the passage_ids. \n",
        "\n",
        "In this section, you have to implement the following: \n",
        "\n",
        "* Load the queries from the query file into a datastructure\n",
        "* Load the query feedback passages into a datastructure.\n",
        "\n",
        "You can use any additional datastructures than the suggested ones for your implementation. \n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XDsPg_A8oZlF",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4bf733a5-cf27-450b-d1cd-33a382f2730a"
      },
      "source": [
        "from collections import defaultdict\n",
        "''' \n",
        "This function is used to load query file information into datastructure(s).\n",
        "Return Variables: \n",
        "queries - mapping from queryid to querytext\n",
        "'''\n",
        "\n",
        "def loadQueries(queries_file):\n",
        "  #enter your code here \n",
        "  queries = defaultdict()\n",
        "  file = open(queries_file, \"r\")\n",
        "  for q in file:\n",
        "    temp = q.split()\n",
        "    queries[temp[0]] = temp[1:]\n",
        "  file.close()\n",
        "  return queries \n",
        "\n",
        "\n",
        "'''\n",
        "This function is used to load feedback passages corresponding to the queries into a datastructure.\n",
        "The file format is given below:\n",
        "\"query_id passage_id1 passage_id2 .....   passage_id10\"\n",
        "The entries are space separated. \n",
        "\n",
        "Return Variables:\n",
        "num_queries - number of queries in the file\n",
        "feedback_pass - mapping from queryid to list of feedback passages                \n",
        "'''\n",
        "\n",
        "\n",
        "def loadFeedbackPass(query_pass):\n",
        "     #enter your code here\n",
        "     feedback_pass = {}\n",
        "     file = open(query_pass, \"r\")\n",
        "     for q in file:\n",
        "        temp = q.split()\n",
        "        feedback_pass[temp[0]] = temp[1:]\n",
        "     file.close()\n",
        "     return feedback_pass\n",
        "\n",
        "\n",
        "\n",
        "queries = loadQueries(queries_file)\n",
        "feedback_pass = loadFeedbackPass(query_pass)\n",
        "\n",
        "\n",
        "print ('Total Num of queries in the query file  : {0}'.format(len(queries)))\n",
        "print ('Total Num of queries in the feedback file  : {0}'.format(len(feedback_pass)))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total Num of queries in the query file  : 5\n",
            "Total Num of queries in the feedback file  : 5\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lE5LNkC_Nz1j"
      },
      "source": [
        "\n",
        "In the cell below, an inverted index with count has been created in memory. Please run the cell and use the variables for implementing the relevance feedback models. "
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "jGIELwv9N7WI",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "897e86ec-3dee-4052-f837-ab8bc468226c"
      },
      "source": [
        "'''\n",
        "Store the feedback docids\n",
        "'''\n",
        "\n",
        "def storeFeedbackPass(query_pass):\n",
        "    feedback_pass_ids = {}\n",
        "    for line in open(query_pass):\n",
        "      row = line.strip().split(' ')      \n",
        "      for p in row[1:]:\n",
        "        if p not in feedback_pass_ids:\n",
        "          feedback_pass_ids[p]=0\n",
        "        feedback_pass_ids[p]+=1\n",
        "    return feedback_pass_ids\n",
        "\n",
        "feedback_pass_ids = storeFeedbackPass(query_pass)\n",
        "\n",
        "\n",
        "'''\n",
        "An inverted index with count information. \n",
        "'''\n",
        "class indexCount:\n",
        "   pcount = 0 \n",
        "   ctf = {}\n",
        "   sumdl = 0\n",
        "   avgdl = 0  \n",
        "   doclen = {}\n",
        "   index = {}\n",
        "   probctf = {}\n",
        "   feedback_pass_contents = {}\n",
        "   \n",
        "   def __init__(self, col):\n",
        "     self.col = col\n",
        "     \n",
        "   \n",
        "   def create_index(self):\n",
        "     for line in open(self.col):    \n",
        "       pid,ptext = line.strip().split('\\t')\n",
        "       self.pcount+=1 \n",
        "       \n",
        "       if pid not in self.doclen:\n",
        "           self.doclen[pid]=0\n",
        "       pfreq = {}\n",
        "       for term in ptext.split(' '):\n",
        "           self.doclen[pid]+=1 \n",
        "           \n",
        "           if term not in pfreq:\n",
        "              pfreq[term]=0\n",
        "           pfreq[term]+=1\n",
        "       \n",
        "       \n",
        "       for k,v in pfreq.items():\n",
        "        if k not in self.index:\n",
        "          self.index[k]={}      \n",
        "        \n",
        "        self.index[k][pid]=v \n",
        "\n",
        "       if pid in feedback_pass_ids:\n",
        "          self.feedback_pass_contents[pid]=ptext\n",
        "       \n",
        "     \n",
        "buildIndex = indexCount(col)      \n",
        "buildIndex.create_index()\n",
        "\n",
        "\n",
        "''' \n",
        "inverted index with count: nested dict with term and passage_id as key\"\n",
        "Example - {'the': {'2020338_0:11', '3174498_1:4'}} \n",
        "'''  \n",
        "index = buildIndex.index\n",
        "\n",
        "#total number of passages in the collection \n",
        "num_passages = buildIndex.pcount\n",
        "\n",
        "#dict with passageId as key and number of terms in the passage as value  \n",
        "doclen = buildIndex.doclen\n",
        "\n",
        "#dict with passage id as key and passage text as value for feedback passages\n",
        "feedback_pass_contents = buildIndex.feedback_pass_contents\n",
        "\n",
        "print('Total number of passages in the collection :{0}'.format(num_passages))\n",
        "print('Total number of feedback passages :{0}'.format(len(feedback_pass_contents)))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total number of passages in the collection :403492\n",
            "Total number of feedback passages :50\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "HfbdH1gB-v_y"
      },
      "source": [
        "# 2 : Query Language Model (20 points)\n",
        "\n",
        "In the cell below, calculate Maximum Likelihood Estimates for the Query Language Model, as follows:\n",
        "\n",
        "$P_{MLE}(t|q)$ = $\\frac{count(t,q)}{|q|}$ \n",
        "\n",
        "$count(t,q)$ - Number of times term $t$ appears in query $q$\n",
        "\n",
        "$|q|$ - Number of tokens in query $q$\n",
        "\n",
        "Calculate the estimates for all queries.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "sFBeVDCqCOW7",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "e0746fe2-efcf-42df-903c-7ee7f470e9ca"
      },
      "source": [
        "''' \n",
        "In this function implement mle estimates for all queries.\n",
        "Return Variables: \n",
        "  mle_queries - mapping from queryid to mle estimates. The mle estimates for each query is a dict from each query word to its MLE probability.\n",
        "'''\n",
        "\n",
        "def calcMleQueries(queries):\n",
        "  #enter your code here\n",
        "  mle_queries = defaultdict(dict)\n",
        "  for qid, qterm in queries.items():\n",
        "    fmap = defaultdict(int)\n",
        "    nterm = len(qterm)\n",
        "    for q in qterm:\n",
        "      fmap[q] += 1\n",
        "\n",
        "    for q in qterm:\n",
        "      mle_queries[qid][q] = fmap[q]/nterm\n",
        "\n",
        "  return mle_queries \n",
        "\n",
        "mle_queries = calcMleQueries(queries)  \n",
        "\n",
        "# Hint: the MLE estimates are in the interval [0.10,0.20]\n",
        "print('MLE estimates for qid 3396066 :{0}'.format(mle_queries['3396066']))\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLE estimates for qid 3396066 :{'why': 0.16666666666666666, 'do': 0.16666666666666666, 'airplane': 0.16666666666666666, 'fly': 0.16666666666666666, 'so': 0.16666666666666666, 'high': 0.16666666666666666}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "lYxT6jBrG7JW"
      },
      "source": [
        "# 3 : Relevance Model 1 (RM1) (30 points)\n",
        "\n",
        "In the cell below, implement the RM1 feedback model, as follows. \n",
        "\n",
        "$$P_{RM1}(t|\\theta_{F}) \\propto \\sum_{p \\in F} (p(t|\\theta_{p}) \\prod_{w \\in q} p(w|\\theta_{p}))$$\n",
        "\n",
        "$p(t|\\theta_{p}) = \\frac{count(t,p) + \\delta}{|p| + \\delta|V|}$ ($p(w|\\theta_{p})$ is computed similarly)\n",
        "\n",
        "$\\delta = 0.1$\n",
        "\n",
        "$|V|$: vocabulary size (number of unique words in the vocabulary)\n",
        "\n",
        "$count(t,p)$ - Number of times term $t$ occurs in passage $p$\n",
        "\n",
        "$|p|$ - Number of tokens in passage $p$\n",
        "\n",
        "$F$: Feedback passages\n",
        "\n",
        "For every query, this has to be computed for all unique terms present in feedback passages.\n",
        "\n",
        "**Note:** Once you compute the weights for each term, you should normalize them by dividing by their sum. In other words, the RM1 probabilities for each query should sum to 1.\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "seltwXRX98hm",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "bb1c6dbe-35ae-4d03-da73-7c4a3fa165ca"
      },
      "source": [
        "import collections\n",
        "\n",
        "''' \n",
        "In this function implement RM1 and return words and their probabilities.\n",
        "Return Variables: \n",
        "rm1 - mapping from queryid to RM1 probabilities. \n",
        "The RM1 probabilities for each query is a dict from the words that appear in the feedback passages to their RM1 probability. \n",
        "'''\n",
        "\n",
        "def calcRM1(index,queries,doclen,feedback_pass,feedback_pass_contents):   \n",
        "    #enter your code here \n",
        "    rm1 = defaultdict(dict)\n",
        "    for qid, qterm in queries.items():\n",
        "      uniq = defaultdict(int)\n",
        "      pid = feedback_pass[qid]\n",
        "      prob = 0\n",
        "      \n",
        "      for p in pid:\n",
        "        psplit = feedback_pass_contents[p].split(\" \")\n",
        "        for term in psplit:\n",
        "          uniq[term] += 1\n",
        "      \n",
        "      for t, val in uniq.items():\n",
        "        pprob = 0\n",
        "        for p in pid:\n",
        "          qprob = 1\n",
        "          tp_count = 0\n",
        "          allterms = doclen[p]\n",
        "          \n",
        "          for qi in qterm:\n",
        "            wp_count = 0\n",
        "            if p in index[qi]:\n",
        "              wp_count = index[qi][p]\n",
        "\n",
        "            qprob *= ((wp_count + 0.1)/(allterms + (0.1 * len(index))))\n",
        "                     \n",
        "          if p in index[t]:\n",
        "            tp_count = index[t][p]    \n",
        "\n",
        "          pprob += (((tp_count + 0.1)/(allterms + (0.1 * len(index)))) * qprob)\n",
        "        \n",
        "        rm1[qid][t] = pprob\n",
        "        prob += pprob\n",
        "\n",
        "    for k, v in rm1[qid].items():\n",
        "      rm1[qid][k] = v/prob\n",
        "                  \n",
        "    return rm1 \n",
        "\n",
        "rm1 = calcRM1(index,queries,doclen,feedback_pass,feedback_pass_contents)\n",
        "\n",
        "'''\n",
        "Print out top 20 terms and corresponding probabilities\n",
        "this assumes that the rm1 variable returned is a dict with queryid as key and dict consisting of term and probability values as the value.\n",
        "You can alter this based on your implementation.\n",
        "'''\n",
        "\n",
        "rm1_scores = {} \n",
        "rm1_final = {}\n",
        "for k,v in rm1.items():\n",
        "    if k not in rm1_final:\n",
        "      rm1_final[k]=[]\n",
        "    if k not in rm1_scores:\n",
        "      rm1_scores[k]={}  \n",
        "    sorted_p = sorted(v.items(), key=lambda x: x[1], reverse=True)\n",
        "    sorted_dict = collections.OrderedDict(sorted_p)\n",
        "    for t,s in sorted_dict.items():\n",
        "        rm1_final[k].append(t+\":\"+str(s)) \n",
        "        rm1_scores[k][t]=s\n",
        "\n",
        "''' Hint: The probability value for the top (1st) term is in the range [0.081,0.083]\n",
        "          The probability value for the 20th term is in the range [0.0076,0.0078]'''\n",
        "print('Top 20 Feedback terms and their RM1 probabilities for qid 3396066 :{0}'.format(rm1_final['3396066'][:20]))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 20 Feedback terms and their RM1 probabilities for qid 3396066 :['the:0.08201915132041583', 'to:0.03889613136203955', 'a:0.038125031057436296', 'helicopter:0.030245917173091285', 'of:0.025662950681680185', 'and:0.024377340618260992', 'in:0.017980664332681986', 'can:0.016712341975101054', 'you:0.011984003910296985', 'that:0.011835938393553782', 'wings:0.011446867894048711', 'rotor:0.011434260221575728', 'are:0.010587661560101626', 'on:0.010233185208287796', 'control:0.010180149758141356', 'spin:0.010180149758141356', 'is:0.009495177908547764', 'fly:0.008124808252820954', 's:0.007781753950717449', 'engine:0.007672588083067976']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "8tNwo7xyEIr8"
      },
      "source": [
        "# 4 : Relevance Model 3 (RM3) (30 points)\n",
        "\n",
        "In the cell below, implement RM3 feedback model\n",
        "\n",
        "$$P_{RM3}(t|\\theta_{F}) = \\alpha P_{RM1}(t|\\theta_{F}) + (1-\\alpha) P_{MLE}(t|q)$$\n",
        "\n",
        "$P_{RM1}(t|\\theta_{F})$ - Probability score returned by RM1 model in Question 3\n",
        "\n",
        "$P_{MLE}(t|q)$ - Query Likelihood estimate calculated in Question 2 \n",
        "\n",
        "$\\alpha = 0.5$\n",
        " \n",
        "For every query, this has to be computed for all unique terms present in feedback passages and the query text."
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yP5SivF3H6Mw",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "a4f2b8b7-b132-4ae7-b00b-76073687803d"
      },
      "source": [
        "''' \n",
        "In this function implement RM1 and return words and their probabilities.\n",
        "Return Variables: \n",
        "rm3 - mapping from queryid to RM1 probabilities. The RM3 probabilities for each query is a dict from the words that appear in the feedback passages or the query to their RM3 probability. \n",
        "'''\n",
        "import collections\n",
        "\n",
        "def calcRM3(rm1_scores,mle_queries,queries,doclen,feedback_pass,feedback_pass_contents):\n",
        "    #enter your code here \n",
        "    rm3 = defaultdict(dict)\n",
        "    for qid, qtext in queries.items():\n",
        "      uniq = defaultdict(int)\n",
        "      uniq_pid = feedback_pass[qid]\n",
        "\n",
        "      for p in uniq_pid:\n",
        "        pfb = feedback_pass_contents[p].split(\" \")\n",
        "        for i in pfb:\n",
        "          uniq[i] += 1\n",
        "\n",
        "      for qterm in qtext:\n",
        "        uniq[qterm] += 1\n",
        "\n",
        "      for uk in uniq.keys():\n",
        "        p1 = 0\n",
        "        p2 = 0\n",
        "        if uk in rm1_scores[qid]:\n",
        "          p1 = 0.5 * rm1_scores[qid][uk]\n",
        "        if uk in mle_queries[qid]:\n",
        "          p2 = (1 - 0.5) * mle_queries[qid][uk]\n",
        "\n",
        "        rm3[qid][uk] = p1 + p2\n",
        "\n",
        "    return rm3 \n",
        "\n",
        "\n",
        "rm3 = calcRM3(rm1_scores,mle_queries,queries,doclen,feedback_pass,feedback_pass_contents)\n",
        "\n",
        "'''\n",
        "Print out top 20 terms and corresponding probabilities\n",
        "this assumes that the rm3 variable returned is a dict with queryid as key and dict consisting of term and probability values as the value.\n",
        "You can alter this based on your implementation.\n",
        "'''\n",
        "\n",
        "rm3_final = {}\n",
        "for k,v in rm3.items():\n",
        "    if k not in rm3_final:\n",
        "      rm3_final[k]=[]\n",
        "    sorted_p = sorted(v.items(), key=lambda x: x[1], reverse=True)\n",
        "    sorted_dict = collections.OrderedDict(sorted_p)\n",
        "    for t,s in sorted_dict.items():\n",
        "        rm3_final[k].append(t+\":\"+str(s)) \n",
        "        \n",
        "''' Hint: The probability value for the top (1st) term is in the range [0.087,0.088]\n",
        "          The probability value for the 20th term is in the range [0.0050,0.0052]'''\n",
        "print('Top 20 Feedback terms and their RM3 probabilities for qid 3396066 :{0}'.format(rm3_final['3396066'][:20]))\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top 20 Feedback terms and their RM3 probabilities for qid 3396066 :['fly:0.0873957374597438', 'so:0.08623512280241481', 'airplane:0.08608183924437131', 'do:0.08538803626235386', 'high:0.08415062068953452', 'why:0.08350777780768794', 'the:0.041009575660207916', 'to:0.019448065681019776', 'a:0.019062515528718148', 'helicopter:0.015122958586545642', 'of:0.012831475340840092', 'and:0.012188670309130496', 'in:0.008990332166340993', 'can:0.008356170987550527', 'you:0.005992001955148493', 'that:0.005917969196776891', 'wings:0.005723433947024356', 'rotor:0.005717130110787864', 'are:0.005293830780050813', 'on:0.005116592604143898']\n"
          ]
        }
      ]
    }
  ]
}
